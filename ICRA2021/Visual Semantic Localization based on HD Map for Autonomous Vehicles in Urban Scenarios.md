"Visual Semantic Localization based on HD Map for Autonomous Vehicles in Urban Scenarios", Huayou Wang*, Changliang Xue*, Yanxing Zhou, Feng Wen and Hongbo Zhang, ICRA, 2021.

自动驾驶中精确的、鲁棒的定位非常重要。传统视觉方法难以应对光照、天气、视角、形状变化，当这些条件发生变化时，特征点通常无法匹配上。本文提出基于语义的定位，语义信息具有较好的鲁棒性，以应对这些条件变化。具体实现上，一是在使用结构一致性、全局模式一致性、时间一致性来提升匹配精度（Data Association），二是采用滑窗因子图优化框架融合数据关联、里程计观测。结果：定位误差，行进方向上0.43m，横向0.12m，偏航0.11°。

困难场景：峡谷，隧道，高架。GNSS在开放场景下，可以取得厘米级精度。但是在城市高楼林立环境中，遮挡、多路径效应，都使得GNSS结果十分不准确。GNSS+IMU可以解决部分问题，但长时间累积漂移也会导致误差过大。为了解决漂移问题，引入了先验地图，比如高精地图、特征点地图。那点云地图的存储是个大问题，特征点地图又无法解决光照、天气、视角、形状变化的问题。因此有了本文的基于语义匹配的方案。语义信息相对比较鲁棒。

related work
基于传统视觉特征的方法，一笔带过了。
基于语义特征的方法，语义特征包括：路标、交通信号灯、交通标识牌、灯柱等。

DA流程
1、采样pose，重投影
初始估计pose周围采集一堆候选pose，将map中的点投影到pose对应图像坐标系下
2、粗匹配
检测到的特征点记为perceived，重投影的特征点记为reprojection，首先特征点横向排序，按序匹配
特征点的匹配，涉及到的参数包括（物体类别，得分，包围盒），一个公式来计算相似度
对于pose的评价，该pose下所有特征点匹配误差，以及匹配成功的数量来计算
3、因子图优化
搞成一个因子图，一个复杂的优化公式
4、特征跟踪
连续帧之间的特征跟踪，与3类似，一起优化了吧
5、滑窗优化
一段时间内的同一个特征点，优化啥的